{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# Create a connection to the database\n",
    "db_connection = sqlite3.connect('../experiment.db')\n",
    "\n",
    "# set info level logging\n",
    "from logging import basicConfig, INFO, getLogger\n",
    "basicConfig(level=INFO)\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming the notebook is in the same directory as the 'custom' package\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_data(conn):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        re.test_run_id,\n",
    "        tr.description as test_run_name,\n",
    "        re.question_id,\n",
    "        q.question as question_content,\n",
    "        re.response_id,\n",
    "        r.response as response_content,\n",
    "        re.test_eval_config_id,\n",
    "        re.eval_score,\n",
    "        ef.name as eval_function_name\n",
    "    FROM response_evals re\n",
    "    JOIN test_runs tr ON re.test_run_id = tr.id\n",
    "    JOIN questions q ON re.question_id = q.id\n",
    "    JOIN responses r ON re.response_id = r.id\n",
    "    JOIN test_eval_configs tec ON re.test_eval_config_id = tec.id\n",
    "    JOIN eval_functions ef ON tec.eval_function_id = ef.id\n",
    "    WHERE tr.description = 'wiqiqa_rag'\n",
    "    \"\"\"\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "def analyze_data2(df):\n",
    "    # Basic statistics\n",
    "    print(\"Basic Statistics:\")\n",
    "    print(df['eval_score'].describe())\n",
    "    \n",
    "    # Average score by test run and evalfunction\n",
    "    avg_by_config = df.groupby(['test_run_name', 'eval_function_name'])['eval_score'].mean().sort_values(ascending=False)\n",
    "    print(\"\\nAverage Score by Eval Config:\")\n",
    "    print(avg_by_config)\n",
    "\n",
    "    # Boxplot of scores by test run and eval function\n",
    "    df.boxplot(column='eval_score', by=['test_run_name', 'eval_function_name'], rot=90)\n",
    "    plt.title('Boxplot of Evaluation Scores by Test Run and Eval Function')\n",
    "    plt.suptitle('')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_data3(df):\n",
    "    # Set the style for all plots\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    # 2. Box plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='eval_function_name', y='eval_score', data=df)\n",
    "    plt.title('Box Plot of Scores by Evaluation Function')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('box_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Kernel Density Estimation (KDE) plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for func in df['eval_function_name'].unique():\n",
    "        sns.kdeplot(df[df['eval_function_name'] == func]['eval_score'], shade=True, label=func)\n",
    "    plt.title('Kernel Density Estimation of Scores by Evaluation Function')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kde_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Heatmap of average scores\n",
    "    pivot_df = df.pivot_table(values='eval_score', index='test_run_name', \n",
    "                              columns='eval_function_name', aggfunc='mean')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "    plt.title('Heatmap of Average Scores by Test Run and Evaluation Function')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 5. Summary statistics\n",
    "    summary_stats = df.groupby('eval_function_name')['eval_score'].describe()\n",
    "    summary_stats.to_csv('summary_statistics.csv')\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(summary_stats)\n",
    "\n",
    "def analyze_data(df):\n",
    "    # Set the style for all plots\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    \n",
    "    # Heatmap of scores by test function\n",
    "    # Create score bins\n",
    "    decimal_precision = 2\n",
    "    score_bins = np.round(np.linspace(0, 1, 11), decimal_precision)\n",
    "    bin_labels = [f\"{score:.{decimal_precision}f}\" for score in score_bins[:-1]]\n",
    "\n",
    "    df['score_bin'] = pd.cut(df['eval_score'], bins=score_bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "    # Create a pivot table\n",
    "    pivot_data = df.pivot_table(\n",
    "        values='eval_score', \n",
    "        index='score_bin', \n",
    "        columns='eval_function_name', \n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    ).sort_index(ascending=False)\n",
    "\n",
    "    # Normalize the data (optional, but helps in visualizing the distribution)\n",
    "    #pivot_data_normalized = pivot_data.div(pivot_data.sum(axis=0), axis=1)\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_data, cmap=\"Blues\", annot=True, fmt='.2f', cbar_kws={'label': 'Normalized Count'})\n",
    "\n",
    "    plt.title(\"Distribution of Evaluation Scores by Test Function\")\n",
    "    plt.xlabel(\"Test Function Name\")\n",
    "    plt.ylabel(\"Score Range\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Summary statistics\n",
    "    summary_stats = df.groupby('eval_function_name')['eval_score'].describe()\n",
    "    summary_stats.to_csv('summary_statistics.csv')\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(summary_stats)\n",
    "\n",
    "df = get_data(db_connection)\n",
    "analyze_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
