{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Notebook - Data from files\n",
    "\n",
    "This notebook will illustrate how to use a file as a Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# Create a connection to the database\n",
    "db_connection = sqlite3.connect('experiment.db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization of Datasources\n",
    "Here we initialize each datasource with example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from packages.data.src.eval_data.models.datasource import DatasourceModel, DatasourceType\n",
    "\n",
    "# Create an instance of DatasourceModel\n",
    "datasource_name = \"sample-financial-data\"\n",
    "if datasource := DatasourceModel(db_connection).get_datasource_by_name(datasource_name):\n",
    "    print(f\"Datasource {datasource_name} loaded - ID: {datasource.id}\")\n",
    "else:\n",
    "    datasource = DatasourceType(name=datasource_name, description=\"Sample financial data in PDF format\")\n",
    "    datasource.id = DatasourceModel(db_connection).add_datasource(datasource)\n",
    "    print(f\"Datasource {datasource_name} created - ID: {datasource.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read files into documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Document\n",
    "from typing import List\n",
    "\n",
    "from documents import load_documents_from_path, save_documents_to_db\n",
    "\n",
    "# We will load all pdf documents in the following directory\n",
    "DATA_PATH = \"datasets/fin\"\n",
    "\n",
    "print(f\"Loading documents from {DATA_PATH}...\")\n",
    "documents: List[Document] = load_documents_from_path(DATA_PATH)\n",
    "print(f\"Number of documents loaded from {DATA_PATH}: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make Question-Answer set\n",
    "Generate Questions and Correct Answers from the loaded Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Questions and Answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from generator import generate_testset\n",
    "from datasets import Dataset\n",
    "\n",
    "from eval_data.models.question import QuestionModel, QuestionType\n",
    "from eval_data.models.document import DocumentModel, DocumentType\n",
    "\n",
    "from database import sog_document, sog_qaset\n",
    "\n",
    "question_model = QuestionModel(db_connection)\n",
    "print(f\"Processing {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    print(f\"Processing Document ID: {doc.id_}\")\n",
    "\n",
    "    # Get or Create the Document\n",
    "    document = sog_document(db_connection, doc, datasource.id)\n",
    "    \n",
    "    qaset = sog_qaset(db_connection, doc, datasource.id, document.id)\n",
    "\n",
    "    # Generate the actual QA Set data\n",
    "    qa_dataset: Dataset = generate_testset([doc], test_size=5)\n",
    "    try:\n",
    "        questions = qa_dataset[\"question\"]\n",
    "        answers = qa_dataset[\"ground_truth\"]\n",
    "        print(f\"Number of questions: {len(questions)}\")\n",
    "        print(f\"Number of answers: {len(answers)}\")\n",
    "    except KeyError:\n",
    "        print(\"No questions and answers generated\")\n",
    "        print(qa_dataset.column_names)\n",
    "        continue\n",
    "\n",
    "    # Save the questions and answers to the database\n",
    "    for question, answer in zip(questions, answers):\n",
    "        question = QuestionType(\n",
    "            qaset_id=qaset.id,\n",
    "            document_id=document.id,\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "        )\n",
    "        question_id = question_model.add_question(question)\n",
    "        print(f\"Question added with ID: {question_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
