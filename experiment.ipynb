{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Your Server\n",
    "### run the following in terminal to start the API server\n",
    "\n",
    "`make start-server`\n",
    "\n",
    "This server will allow us to save our experiment data.\n",
    "\n",
    "# Running RAG Evaluations\n",
    "\n",
    "The process of evaluating your RAG platform consists of the following steps and (Outputs):\n",
    "\n",
    "1. Get data for our RAG to search (Documents)\n",
    "2. Create a dataset of questions and ground truths (Q-A Dataset)\n",
    "3. Use your RAG-LLM system to answer the questions (Completions, Context)\n",
    "4. Use eval tools to calculate metrics based on previous output (Metrics)\n",
    "\n",
    "## *BioASQ-QA: A manually curated corpus for Biomedical Question Answering*\n",
    "For this example we will download a dataset built for RAG Q/A evaluation, which will save us some time.\n",
    "\n",
    "| Description            | Link                                                                 |\n",
    "|------------------------|----------------------------------------------------------------------|\n",
    "| Information about dataset | [Nature Article > scientific data > data descriptors ](https://www.nature.com/articles/s41597-023-02068-4#) |\n",
    "| Download source        | [Hugging Face Datasets](https://huggingface.co/datasets/rag-datasets/rag-mini-bioasq) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(\"DEBUG\")\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "from eval_scripts.utils import post_dataset, post_qasets, post_documents\n",
    "from eval_data.models import DatasetType, DocumentType, QASetType\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Dataset in our db\n",
    "dataset = DatasetType(\n",
    "    name=\"BioASQ\",\n",
    "    description=\"Manually curated set of biomedical Documents, Questions, and Answers\",\n",
    ")\n",
    "\n",
    "result = post_dataset(dataset.to_dict())\n",
    "if result.get(\"id\"):\n",
    "    dataset_id = result[\"id\"]\n",
    "elif result.get(\"error\"):\n",
    "    raise Exception(result[\"error\"])\n",
    "else:\n",
    "    print(result)\n",
    "    raise Exception(\"Failed to create dataset\")\n",
    "\n",
    "print(f\"Created dataset with id: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get a ready QA set from hugging face\n",
    "\n",
    "The BioASQ dataset contains a Q/A set already, which is very valuable for our evaluation because it is a curated set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deubbing, set the dataset_id to the id of the dataset you want to update\n",
    "dataset_id=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Loading QA dataset\")\n",
    "dataset = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")['test']\n",
    "\n",
    "qaset = QASetType(\n",
    "    dataset_id=dataset_id,\n",
    "    name=\"BioASQ Question Answer Set\",\n",
    "    location=dataset.cache_files[0][\"filename\"] # This will be a location of a '.arrow' file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = post_qasets(qaset.to_dict())\n",
    "if result.get(\"id\"):\n",
    "    qaset_id = result[\"id\"]\n",
    "elif result.get(\"error\"):\n",
    "    raise Exception(result[\"error\"])\n",
    "else:\n",
    "    print(result)\n",
    "    raise Exception(\"Failed to create QA set\")\n",
    "\n",
    "print(f\"Created QA Set(s): {qaset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from eval_scripts.utils import build_query_engine\n",
    "\n",
    "# Load the documents from HuggingFace data\n",
    "logger.info(\"Loading dataset text corpus\")\n",
    "doc_loader = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")\n",
    "\n",
    "# Compose nodes for llama_index.core.index.VectorStoreIndex\n",
    "#logger.info(\"Constructing Documents for query engine\")\n",
    "#documents = [ TextNode(text=doc[\"passage\"], id_=doc[\"id\"]) for doc in doc_loader[\"passages\"] ]\n",
    "\n",
    "# Create a VectorStoreIndex\n",
    "# This will run embeddings on all the documents and persist the index to disk\n",
    "query_engine = build_query_engine(doc_loader[\"passages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Answer the evaluation questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If necessary, load the query engine from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_scripts.utils import load_query_engine\n",
    "\n",
    "# Load the query engine from a persisted index\n",
    "query_engine = load_query_engine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate responses using the query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_scripts.ragas_complete import generate_responses\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "for i in range(0, len(dataset['question']), BATCH_SIZE):\n",
    "    responses = generate_responses(query_engine, dataset['question'][i:i+BATCH_SIZE], test_answers=None)\n",
    "    print(responses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from eval_scripts.ragas_complete import generate_responses\n",
    "from eval_scripts.utils import build_query_engine, count_tokens\n",
    "import math\n",
    "\n",
    "# Load the documents from HuggingFace data\n",
    "logger.info(\"Loading dataset text corpus\")\n",
    "doc_loader = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")\n",
    "    \n",
    "\n",
    "# Compose nodes for llama_index.core.index.VectorStoreIndex\n",
    "#logger.info(\"Constructing Documents for query engine\")\n",
    "#documents = [ TextNode(text=doc[\"passage\"], id_=doc[\"id\"]) for doc in doc_loader[\"passages\"] ]\n",
    "\n",
    "# Create a VectorStoreIndex\n",
    "# This will run embeddings on all the documents\n",
    "query_engine = build_query_engine(doc_loader[\"passages\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_questions = dataset[\"question\"]\n",
    "\n",
    "if \"ground_truth\" in dataset.column_names:\n",
    "    test_answers = dataset[\"ground_truth\"]\n",
    "else:\n",
    "    test_answers = dataset[\"answer\"]\n",
    "\n",
    "\n",
    "result_ds = generate_responses(query_engine1, test_questions, test_answers)\n",
    "\n",
    "result_ds.save_to_disk(PATH_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
